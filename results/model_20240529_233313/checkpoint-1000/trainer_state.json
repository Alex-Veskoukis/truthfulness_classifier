{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.3698399326032016,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 1.7916,
      "step": 10
    },
    {
      "epoch": 0.07,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 1.7917,
      "step": 20
    },
    {
      "epoch": 0.1,
      "learning_rate": 3e-06,
      "loss": 1.7919,
      "step": 30
    },
    {
      "epoch": 0.13,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.7919,
      "step": 40
    },
    {
      "epoch": 0.17,
      "learning_rate": 5e-06,
      "loss": 1.7918,
      "step": 50
    },
    {
      "epoch": 0.2,
      "learning_rate": 6e-06,
      "loss": 1.7917,
      "step": 60
    },
    {
      "epoch": 0.24,
      "learning_rate": 7.000000000000001e-06,
      "loss": 1.7924,
      "step": 70
    },
    {
      "epoch": 0.27,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.7913,
      "step": 80
    },
    {
      "epoch": 0.3,
      "learning_rate": 9e-06,
      "loss": 1.7921,
      "step": 90
    },
    {
      "epoch": 0.34,
      "learning_rate": 1e-05,
      "loss": 1.791,
      "step": 100
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 1.7911,
      "step": 110
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.2e-05,
      "loss": 1.7902,
      "step": 120
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.7907,
      "step": 130
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.7905,
      "step": 140
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.5e-05,
      "loss": 1.7891,
      "step": 150
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.7839,
      "step": 160
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.788,
      "step": 170
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8e-05,
      "loss": 1.7835,
      "step": 180
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.9e-05,
      "loss": 1.7787,
      "step": 190
    },
    {
      "epoch": 0.67,
      "learning_rate": 2e-05,
      "loss": 1.7765,
      "step": 200
    },
    {
      "epoch": 0.71,
      "learning_rate": 2.1e-05,
      "loss": 1.7717,
      "step": 210
    },
    {
      "epoch": 0.74,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.7666,
      "step": 220
    },
    {
      "epoch": 0.78,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.7737,
      "step": 230
    },
    {
      "epoch": 0.81,
      "learning_rate": 2.4e-05,
      "loss": 1.7597,
      "step": 240
    },
    {
      "epoch": 0.84,
      "learning_rate": 2.5e-05,
      "loss": 1.7561,
      "step": 250
    },
    {
      "epoch": 0.88,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.7537,
      "step": 260
    },
    {
      "epoch": 0.91,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.7661,
      "step": 270
    },
    {
      "epoch": 0.94,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.7551,
      "step": 280
    },
    {
      "epoch": 0.98,
      "learning_rate": 2.9e-05,
      "loss": 1.731,
      "step": 290
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.7281079292297363,
      "eval_runtime": 67.2276,
      "eval_samples_per_second": 35.313,
      "eval_steps_per_second": 4.418,
      "step": 296
    },
    {
      "epoch": 1.01,
      "learning_rate": 3e-05,
      "loss": 1.7318,
      "step": 300
    },
    {
      "epoch": 1.04,
      "learning_rate": 3.1e-05,
      "loss": 1.7169,
      "step": 310
    },
    {
      "epoch": 1.08,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.7411,
      "step": 320
    },
    {
      "epoch": 1.11,
      "learning_rate": 3.3e-05,
      "loss": 1.7127,
      "step": 330
    },
    {
      "epoch": 1.15,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.6972,
      "step": 340
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.5e-05,
      "loss": 1.7164,
      "step": 350
    },
    {
      "epoch": 1.21,
      "learning_rate": 3.6e-05,
      "loss": 1.7276,
      "step": 360
    },
    {
      "epoch": 1.25,
      "learning_rate": 3.7e-05,
      "loss": 1.7181,
      "step": 370
    },
    {
      "epoch": 1.28,
      "learning_rate": 3.8e-05,
      "loss": 1.74,
      "step": 380
    },
    {
      "epoch": 1.31,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.7102,
      "step": 390
    },
    {
      "epoch": 1.35,
      "learning_rate": 4e-05,
      "loss": 1.7708,
      "step": 400
    },
    {
      "epoch": 1.38,
      "learning_rate": 4.1e-05,
      "loss": 1.6987,
      "step": 410
    },
    {
      "epoch": 1.42,
      "learning_rate": 4.2e-05,
      "loss": 1.7061,
      "step": 420
    },
    {
      "epoch": 1.45,
      "learning_rate": 4.3e-05,
      "loss": 1.7294,
      "step": 430
    },
    {
      "epoch": 1.48,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.7095,
      "step": 440
    },
    {
      "epoch": 1.52,
      "learning_rate": 4.5e-05,
      "loss": 1.7108,
      "step": 450
    },
    {
      "epoch": 1.55,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.7082,
      "step": 460
    },
    {
      "epoch": 1.58,
      "learning_rate": 4.7e-05,
      "loss": 1.7469,
      "step": 470
    },
    {
      "epoch": 1.62,
      "learning_rate": 4.8e-05,
      "loss": 1.6898,
      "step": 480
    },
    {
      "epoch": 1.65,
      "learning_rate": 4.9e-05,
      "loss": 1.7033,
      "step": 490
    },
    {
      "epoch": 1.68,
      "learning_rate": 5e-05,
      "loss": 1.6599,
      "step": 500
    },
    {
      "epoch": 1.72,
      "learning_rate": 4.9489795918367346e-05,
      "loss": 1.6707,
      "step": 510
    },
    {
      "epoch": 1.75,
      "learning_rate": 4.89795918367347e-05,
      "loss": 1.699,
      "step": 520
    },
    {
      "epoch": 1.79,
      "learning_rate": 4.846938775510204e-05,
      "loss": 1.713,
      "step": 530
    },
    {
      "epoch": 1.82,
      "learning_rate": 4.795918367346939e-05,
      "loss": 1.7045,
      "step": 540
    },
    {
      "epoch": 1.85,
      "learning_rate": 4.744897959183674e-05,
      "loss": 1.6899,
      "step": 550
    },
    {
      "epoch": 1.89,
      "learning_rate": 4.6938775510204086e-05,
      "loss": 1.7086,
      "step": 560
    },
    {
      "epoch": 1.92,
      "learning_rate": 4.642857142857143e-05,
      "loss": 1.6967,
      "step": 570
    },
    {
      "epoch": 1.95,
      "learning_rate": 4.591836734693878e-05,
      "loss": 1.6886,
      "step": 580
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.5408163265306124e-05,
      "loss": 1.6677,
      "step": 590
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.691848874092102,
      "eval_runtime": 66.6594,
      "eval_samples_per_second": 35.614,
      "eval_steps_per_second": 4.455,
      "step": 593
    },
    {
      "epoch": 2.02,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 1.7347,
      "step": 600
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.438775510204082e-05,
      "loss": 1.6578,
      "step": 610
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.387755102040816e-05,
      "loss": 1.6567,
      "step": 620
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.336734693877551e-05,
      "loss": 1.6466,
      "step": 630
    },
    {
      "epoch": 2.16,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 1.6441,
      "step": 640
    },
    {
      "epoch": 2.19,
      "learning_rate": 4.234693877551021e-05,
      "loss": 1.654,
      "step": 650
    },
    {
      "epoch": 2.22,
      "learning_rate": 4.183673469387756e-05,
      "loss": 1.6676,
      "step": 660
    },
    {
      "epoch": 2.26,
      "learning_rate": 4.13265306122449e-05,
      "loss": 1.652,
      "step": 670
    },
    {
      "epoch": 2.29,
      "learning_rate": 4.0816326530612245e-05,
      "loss": 1.6496,
      "step": 680
    },
    {
      "epoch": 2.33,
      "learning_rate": 4.0306122448979596e-05,
      "loss": 1.61,
      "step": 690
    },
    {
      "epoch": 2.36,
      "learning_rate": 3.979591836734694e-05,
      "loss": 1.6411,
      "step": 700
    },
    {
      "epoch": 2.39,
      "learning_rate": 3.928571428571429e-05,
      "loss": 1.5667,
      "step": 710
    },
    {
      "epoch": 2.43,
      "learning_rate": 3.8775510204081634e-05,
      "loss": 1.64,
      "step": 720
    },
    {
      "epoch": 2.46,
      "learning_rate": 3.826530612244898e-05,
      "loss": 1.6492,
      "step": 730
    },
    {
      "epoch": 2.49,
      "learning_rate": 3.775510204081633e-05,
      "loss": 1.6249,
      "step": 740
    },
    {
      "epoch": 2.53,
      "learning_rate": 3.724489795918368e-05,
      "loss": 1.6487,
      "step": 750
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.673469387755102e-05,
      "loss": 1.56,
      "step": 760
    },
    {
      "epoch": 2.59,
      "learning_rate": 3.622448979591837e-05,
      "loss": 1.6311,
      "step": 770
    },
    {
      "epoch": 2.63,
      "learning_rate": 3.571428571428572e-05,
      "loss": 1.5964,
      "step": 780
    },
    {
      "epoch": 2.66,
      "learning_rate": 3.520408163265306e-05,
      "loss": 1.5944,
      "step": 790
    },
    {
      "epoch": 2.7,
      "learning_rate": 3.469387755102041e-05,
      "loss": 1.66,
      "step": 800
    },
    {
      "epoch": 2.73,
      "learning_rate": 3.4183673469387755e-05,
      "loss": 1.5683,
      "step": 810
    },
    {
      "epoch": 2.76,
      "learning_rate": 3.36734693877551e-05,
      "loss": 1.5867,
      "step": 820
    },
    {
      "epoch": 2.8,
      "learning_rate": 3.316326530612245e-05,
      "loss": 1.6269,
      "step": 830
    },
    {
      "epoch": 2.83,
      "learning_rate": 3.265306122448979e-05,
      "loss": 1.6228,
      "step": 840
    },
    {
      "epoch": 2.86,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 1.5609,
      "step": 850
    },
    {
      "epoch": 2.9,
      "learning_rate": 3.1632653061224494e-05,
      "loss": 1.6086,
      "step": 860
    },
    {
      "epoch": 2.93,
      "learning_rate": 3.112244897959184e-05,
      "loss": 1.5462,
      "step": 870
    },
    {
      "epoch": 2.97,
      "learning_rate": 3.061224489795919e-05,
      "loss": 1.5545,
      "step": 880
    },
    {
      "epoch": 3.0,
      "learning_rate": 3.0102040816326533e-05,
      "loss": 1.5847,
      "step": 890
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.5793646574020386,
      "eval_runtime": 66.2281,
      "eval_samples_per_second": 35.846,
      "eval_steps_per_second": 4.485,
      "step": 890
    },
    {
      "epoch": 3.03,
      "learning_rate": 2.959183673469388e-05,
      "loss": 1.572,
      "step": 900
    },
    {
      "epoch": 3.07,
      "learning_rate": 2.9081632653061224e-05,
      "loss": 1.5021,
      "step": 910
    },
    {
      "epoch": 3.1,
      "learning_rate": 2.857142857142857e-05,
      "loss": 1.5401,
      "step": 920
    },
    {
      "epoch": 3.13,
      "learning_rate": 2.8061224489795918e-05,
      "loss": 1.5075,
      "step": 930
    },
    {
      "epoch": 3.17,
      "learning_rate": 2.7551020408163265e-05,
      "loss": 1.5418,
      "step": 940
    },
    {
      "epoch": 3.2,
      "learning_rate": 2.7040816326530616e-05,
      "loss": 1.5218,
      "step": 950
    },
    {
      "epoch": 3.24,
      "learning_rate": 2.6530612244897963e-05,
      "loss": 1.5402,
      "step": 960
    },
    {
      "epoch": 3.27,
      "learning_rate": 2.6020408163265307e-05,
      "loss": 1.5781,
      "step": 970
    },
    {
      "epoch": 3.3,
      "learning_rate": 2.5510204081632654e-05,
      "loss": 1.5113,
      "step": 980
    },
    {
      "epoch": 3.34,
      "learning_rate": 2.5e-05,
      "loss": 1.489,
      "step": 990
    },
    {
      "epoch": 3.37,
      "learning_rate": 2.448979591836735e-05,
      "loss": 1.5465,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 458884898721792.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
